{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stahldavid/rosindex/blob/master/Pesquisa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtUAz76-fUOP"
      },
      "source": [
        "# Install Dependencies\n",
        "\n",
        "\n",
        "\n",
        "   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "H2bZo3OjjBBJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install -qU bs4  openai langchain pinecone-client[grpc]\n",
        "!pip install -q gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxFyxsUQfjaP"
      },
      "source": [
        "# Imports\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "H4UgQJ0Efwey"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import langchain\n",
        "from langchain import OpenAI, VectorDBQA\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.document_loaders import DirectoryLoader, UnstructuredFileLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1gERYpsf9M8"
      },
      "source": [
        "# Set API Key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "95ImJQuwf8Jb"
      },
      "outputs": [],
      "source": [
        "\n",
        "#embeddings = OpenAIEmbeddings(openai_api_key=\"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\")\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=\"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\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = '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'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4lEx16GgfRm"
      },
      "source": [
        "# ChatVectorDBChain and Prompt Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kTi_ZAp0glnj"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ChatVectorDBChain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    AIMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from langchain.schema import (\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "\n",
        "system_template=\"\"\"Use the following pieces of context to answer the users question. \n",
        "If you don't know the answer, just say that you don't know, don't try to make up an answer. \n",
        "Answer in Markdown format.\n",
        "Write code in code boxes.\n",
        "----------------\n",
        "{context}\"\"\"\n",
        "messages = [\n",
        "    SystemMessagePromptTemplate.from_template(system_template),\n",
        "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
        "]\n",
        "prompt = ChatPromptTemplate.from_messages(messages)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdqlNYEPgora"
      },
      "source": [
        "# Gradio Interface Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 690
        },
        "id": "yOLQtjkegqks",
        "outputId": "0e729e0e-0588-42c4-c6ce-5192b241ca06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:43: UserWarning: You have unused kwarg parameters in State, please remove them: {'source_documents': ''}\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/components.py:164: UserWarning: Unknown style parameter: height\n",
            "  warnings.warn(f\"Unknown style parameter: {key}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7860, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import pinecone\n",
        "\n",
        "# Initialize an embedding function\n",
        "\n",
        "\n",
        "# Pinecone setup\n",
        "pinecone.init(\n",
        "    api_key=\"ed8a92c3-abd9-42d3-bfd7-f3b7415af62c\",  # find at app.pinecone.io\n",
        "    environment=\"us-east1-gcp\"  # next to api key in console\n",
        ")\n",
        "\n",
        "def create_dataframe(source_documents):\n",
        "    data = []\n",
        "    for doc in source_documents:\n",
        "        page_num = doc.metadata['page']\n",
        "        doc_name = doc.metadata['source']\n",
        "        data.append({'Page Number': page_num, 'Document Name': doc_name})\n",
        "    df = pd.DataFrame(data)\n",
        "    return df.to_string()\n",
        "\n",
        "def unir_textos_documentos(source_documents):\n",
        "    textos = [documento.page_content for documento in source_documents]\n",
        "    texto_unido = ' '.join(textos)\n",
        "    return texto_unido\n",
        "\n",
        "index = None\n",
        "source_documents_chatbot_messages = []\n",
        "\n",
        "\n",
        "\n",
        "def chat(chat_history, message):\n",
        "    # Verifique se o tamanho do chat_history Ã© maior que 3000 caracteres\n",
        "    chat_history_length = sum(len(msg) + len(ans) for msg, ans in chat_history)\n",
        "    if chat_history_length > 12000:\n",
        "        # Remova os primeiros 1000 caracteres do chat_history\n",
        "        removed_chars = 0\n",
        "        while removed_chars < 3000:\n",
        "            msg, ans = chat_history.pop(0)\n",
        "            removed_chars += len(msg) + len(ans)\n",
        "    \n",
        "    source_documents = []\n",
        "    index = pinecone.Index(\"langchain-chat\")\n",
        "\n",
        "    # Initialize a Pinecone vector store\n",
        "    vectorstore = Pinecone(index=index, embedding_function=embeddings.embed_query, text_key=\"text\")\n",
        "\n",
        "    qa = ChatVectorDBChain.from_llm(ChatOpenAI(temperature=0), vectorstore=vectorstore, qa_prompt=prompt, return_source_documents=True)\n",
        "    result = qa({\"question\": message, \"chat_history\": chat_history})\n",
        "    answer = result[\"answer\"]\n",
        "    chat_history.append((message, answer))\n",
        "    source_documents = result['source_documents']\n",
        "    source_documents_text = unir_textos_documentos(source_documents)\n",
        "    df_string = create_dataframe(source_documents)\n",
        "\n",
        "    return chat_history, source_documents, df_string\n",
        "\n",
        "def clear_chat_history(chatbot):\n",
        "    chatbot.clear()\n",
        "    chat_history = []\n",
        "    source_documents = []\n",
        "    \n",
        "    source_documents_chatbot_messages.clear()\n",
        "    return chat_history, source_documents\n",
        "\n",
        "\n",
        "\n",
        "with gr.Blocks(css=\"#chatbot .overflow-y-auto{height:500px}\") as demo:\n",
        "    state = gr.State(source_documents=\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=0.75):\n",
        "            with gr.Tab(\"Chatbot\"):\n",
        "                chatbot = gr.Chatbot([], elem_id=\"chatbot\").style(height=750)\n",
        "                messagem = gr.Textbox(show_label=False, placeholder=\"Enter text and press enter\")\n",
        "        with gr.Column(scale=0.5):\n",
        "            with gr.Tab(\"Source Documents\"):\n",
        "                with gr.Row():\n",
        "                    source_documents_chatbot = gr.Textbox([], elem_id=\"source_documents_text\").style(height=750)\n",
        "                with gr.Row():\n",
        "                    df_textbox = gr.Textbox([], elem_id=\"df_textbox\").style(height=250)\n",
        "\n",
        "    messagem.submit(chat, [chatbot, messagem], [chatbot, source_documents_chatbot, df_textbox])\n",
        "    messagem.submit(lambda: \"\", None, messagem)\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=0.15, min_width=0):\n",
        "            clear_btn = gr.Button(\"Clear\")\n",
        "            clear_btn.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "demo.launch(debug=True)\n",
        "\n",
        "   \n",
        "   \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTnceVmRHvY1u9rnOVFZTu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}